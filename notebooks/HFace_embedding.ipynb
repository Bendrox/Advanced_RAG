{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0302e2de",
   "metadata": {},
   "source": [
    "## 1 - Open source embedding model exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076c7755",
   "metadata": {},
   "source": [
    "Exploring here other \"open source\" embedding models. \n",
    "\n",
    "For this task we will use MTEB that compares 100+ text (and image) embedding models across 1000, languages depending on metrics, languages, tasks, and task types:\n",
    "\n",
    "https://huggingface.co/spaces/mteb/leaderboard\n",
    "\n",
    "MTEB classe les modèles en fonction de  8 types de tâches  : ￼\n",
    "\n",
    "1.\tBitext Mining : trouver des phrases correspondantes dans deux langues différentes.\n",
    "\n",
    "2.\tClassification : attribuer des catégories aux textes.\n",
    "\n",
    "3.\tClustering : regrouper des textes similaires.\n",
    "\n",
    "4.\tPair Classification : déterminer si deux textes sont similaires.\n",
    "\n",
    "5.\tReranking : ordonner une liste de textes en fonction de leur pertinence par rapport à une requête.\n",
    "\n",
    "6.\tRetrieval : retrouver des documents pertinents pour une requête donnée.\n",
    "\n",
    "7.\tSemantic Textual Similarity (STS) : mesurer la similarité sémantique entre deux textes.\n",
    "\n",
    "8.\tSummarization : évaluer la qualité des résumés générés automatiquement. ￼\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce12b6f9",
   "metadata": {},
   "source": [
    "Critères de choix pour le modèle:\n",
    "- Performances en terme de Retrieval\n",
    "- Nombre de tokens maximal à partir de 8191 en raison de la longeur de nos chunks (articles de loi dont la taille très variables)\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b38e32b",
   "metadata": {},
   "source": [
    "A la vue de ces résultats deux choix s'offrent a nous: \n",
    "- Choisir le premier qui globalement offre les meilleurs performances dans le cas des textes juridiques francais.\n",
    "- Choisir le 5 iem qui offre le meilleur rapport "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ce75ff",
   "metadata": {},
   "source": [
    "## 2 - Testing the most efficient model : multilingual-e5-large-instruct (0.5 B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4b4539",
   "metadata": {},
   "source": [
    " Even if this model is ranked at the 5th position it is the lighetest and most efficient one without a significant drop in performance (only 0.5 B param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab8f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fe1cec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdcdd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer= AutoTokenizer.from_pretrained(\"intfloat/multilingual-e5-large-instruct\",token =os.getenv('HF_token'))\n",
    "model= AutoModel.from_pretrained(\"intfloat/multilingual-e5-large-instruct\", token=os.getenv('HF_token'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b133a4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detailed_instruct(task_description: str, query: str) -> str:\n",
    "    return f'Instruct: {task_description}\\nQuery: {query}'\n",
    "\n",
    "task = 'Given a web search query, retrieve relevant passages that answer the query'\n",
    "queries = [\n",
    "    get_detailed_instruct(task, 'how much protein should a female eat'),\n",
    "    get_detailed_instruct(task, '南瓜的家常做法')\n",
    "]\n",
    "documents = [\n",
    "    \"As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day...\",\n",
    "    \"1.清炒南瓜丝 原料:嫩南瓜半个 调料:葱、盐、白糖、鸡精 做法:...\"\n",
    "]\n",
    "input_texts = queries + documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f11763f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m batch_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m(input_texts, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "batch_dict = tokenizer(input_texts, max_length=512, padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ce3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**batch_dict)\n",
    "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd4df1d",
   "metadata": {},
   "source": [
    "Définir la fonction de pooling :\n",
    "Cette fonction effectue une moyenne pondérée par le masque d’attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdcd041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "embeddings = F.normalize(embeddings, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f6b788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0202,  0.0112, -0.0451,  ..., -0.0266, -0.0423,  0.0389],\n",
       "        [ 0.0486,  0.0594,  0.0040,  ..., -0.0214, -0.0263,  0.0198],\n",
       "        [ 0.0198, -0.0023, -0.0366,  ..., -0.0368, -0.0272,  0.0254],\n",
       "        [ 0.0461,  0.0436,  0.0091,  ..., -0.0155, -0.0181,  0.0149]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d51e406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ty/2g_hgfks4nl_84mz496fmn600000gn/T/ipykernel_82697/1230817599.py:1: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3729.)\n",
      "  similarity = torch.matmul(embeddings[0], embeddings[1].T)\n"
     ]
    }
   ],
   "source": [
    "similarity = torch.matmul(embeddings[0], embeddings[1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3d8e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list = embeddings.tolist()  \n",
    "embedding_array = embeddings.cpu().numpy()  # to tbl NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c31e49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02018598,  0.01120441, -0.04514236, ..., -0.02658733,\n",
       "        -0.04230955,  0.03893524],\n",
       "       [ 0.04857629,  0.05938283,  0.00398616, ..., -0.02135831,\n",
       "        -0.0263372 ,  0.01975931],\n",
       "       [ 0.01981018, -0.00233509, -0.03661876, ..., -0.03679116,\n",
       "        -0.02720564,  0.02541652],\n",
       "       [ 0.04608595,  0.04364255,  0.00913067, ..., -0.01546213,\n",
       "        -0.01805959,  0.01493509]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6583c668",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "We choose to use the 5th one (multilingual-e5-large-instrc) since it performing well globally and still good on retreival , reranking and STS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a89d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Advanced_RAG)",
   "language": "python",
   "name": "mon_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
